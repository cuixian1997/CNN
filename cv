import cv2
import numpy as np
from cv2 import BORDER_CONSTANT, THRESH_BINARY, THRESH_BINARY_INV


# 基本图像操作
img = cv2.imread('girl.jpg')
# cv2.imshow('girl',img)
# print(img.shape,img.dtype)
# print(img[0:32,0:32,0])
b,g,r = cv2.split(img)
g = g.reshape((64,64,1))
print(g.dtype)
# print(g.shape)
# cv2.imshow('girl',g)
# cv2.waitKey(0)

img_copy = img.copy()
img_copy[:,:,1] = 0
img_copy[:,:,2] = 0
img_copy = cv2.copyMakeBorder(img,128,128,128,128, borderType=BORDER_CONSTANT, value=50)
# cv2.imshow('girl',img_copy)
# cv2.waitKey(0)

# openCV的数值计算：广播与维度匹配
img_copy = img.copy() + 10
img_copy_cut= img_copy[0:5,0:5,0]
# print(img_copy_cut.shape)
# print(img_copy_cut)
img_copy = cv2.resize(img,(320,320))
# cv2.imshow('copy',img_copy)
# cv2.waitKey(0)

# 图像阈值
ret,dst = cv2.threshold(img,128,255,type=THRESH_BINARY_INV) # 直接生成黑白图
# 阈值，输出图             原图，阈值，最大值，超过阈值取最大值。THRESH_TRUNC :大于阈值的设为阈值
#                                                     THRESH_TOZERO :大于阈值不变，否则为零 THRESH_TOZERO_INV
dst = cv2.resize(dst,(320,320))
# cv2.imshow('heibai',dst)
# cv2.waitKey(0)

# 图像平滑处理，即3*3均值卷积处理，卷积核为1/N
dog = cv2.imread('dog.jpg')
dog = cv2.resize(dog,(512,256))
# cv2.imshow('dog',dog)
# cv2.waitKey(0)
# cv2.destroyAllWindows()
blur = cv2.blur(dog,(32,32))

# 方框滤波基本和blur一致，第二个参数-1表示channel与原图像channel一致，可以进行Normalization操作
box = cv2.boxFilter(dog,3,(32,32),normalize=True)
# 加上归一化就与均值滤波完全一致，不归一化，可能越界，越界就会对255取余


# 高斯滤波：用高斯函数为每个数据上一个权重，然后加权求和，离中心越远权重越低，越近权重越高
# 窗口大小必须为单数，否则找不到中心点了，均值就是0，标准差越大，单个窗口变化幅度越大，图像越模糊
gaussian = cv2.GaussianBlur(dog,(31,31),1)
# 中值滤波
medium = cv2.medianBlur(dog,5)
filter = np.hstack([blur,box,gaussian,medium])
# cv2.imshow('gaussian',filter)
# cv2.waitKey(0)
# cv2.destroyAllWindows()

# 形态学处理
# 腐蚀操作：对图像的变色边界进行腐蚀扩展，黑色腐蚀白色
erosion_kernel= np.ones((3,3),np.uint8)
erosion = cv2.erode(cv2.resize(img,(320,320)),erosion_kernel,iterations=1)
cv2.imshow('s',erosion)
cv2.waitKey(0)
cv2.destroyAllWindows()
# 膨胀操作：腐蚀操作消去了一些杂物也对原图有损害，膨胀回去就好了，白色扩展黑色，但是会对原来的信息有损害
dilate_kernel= np.ones((3,3),np.uint8)
dilate = cv2.dilate(cv2.resize(img, (320,320)), dilate_kernel, iterations=5)
# cv2.imshow('s',dilate)
# cv2.waitKey(0)
# cv2.destroyAllWindows()
# 开运算：先腐蚀（白色没有了）再膨胀（白色已经很少了，膨胀也没用）：去掉图像的毛刺，去掉细小的高亮区域
kernel = np.ones((3,3),np.uint8)
open = cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel)
# 闭运算：先膨胀（白色扩大）再腐蚀（很多白色，腐蚀一点而已）：加重图像的毛刺，但是对图像原本数据不会有太大的影响，可以高亮细小的白色区域
close = cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernel)

# 梯度计算:膨胀结果-腐蚀结果，就是边界信息
gradient = cv2.morphologyEx(cv2.resize(img,(320,320)),cv2.MORPH_GRADIENT,kernel)
cv2.imshow('GRADIENT',gradient)
cv2.waitKey(0)
cv2.destroyAllWindows()

# 礼帽：原始数据-开运算结果：删去原内容，只保留毛刺，突出一些细线，比如黑底白字，只有毛刺白线了
tophat = cv2.morphologyEx(cv2.resize(img,(320,320)),cv2.MORPH_TOPHAT,kernel)
# 黑帽：闭运算结果-原始数据：只剩下原始图像的没有毛刺下的轮廓，内部就没有了，整个图像很黑，只有白色的轮廓线，毛刺也没了
blackhat = cv2.morphologyEx(cv2.resize(img,(320,320)),cv2.MORPH_BLACKHAT,kernel)

cv2.imshow('s',blackhat )
cv2.waitKey(0)
cv2.destroyAllWindows()




import cv2
import numpy as np
from cv2 import BORDER_CONSTANT, THRESH_BINARY, THRESH_BINARY_INV

# 梯度计算
'''
sobel算子
Gx：水平卷积算子：[-1,0,1]          :A右边减左边
               [-2, 0 ,2]  .* A 
               [-1,0,1]
Gy:竖直卷积算子 [-1 -2 -1]         : A下减上
              [0   0  0]   .* A 
              [1   2   ]
openCV的默认取值范围是0-255，如果是负值，就会置0
两个方向求出梯度以后，在求中和，可以是l1，也可以是l2
'''
img = cv2.imread('girl.jpg')
img  = cv2.resize(img,(320,320))
sobelx = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=3)
sobely = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=3)
sobel = cv2.addWeighted(sobelx,0.5,sobely,0.5,0)
#                         原图，dx，dy即计算方向，kernel
# sobel中有负数，但是openCV直接置零了，取绝对值即可，置零就是黑的，修改一下
# soble = cv2.con
# cv2.waitKey(0)
# cv2.destroyAllWindows()
# 拉普拉斯算子
# laplace = cv2.Laplacian(img,cv2.CV_32F,ksize=5)
# cv2.imshow('s',img)
# cv2.imshow('s2',laplace)
# cv2.waitKey(0)
# cv2.destroyAllWindows()


'''
Canny边缘检测算法：
1、高斯滤波
2、每个像素点的梯度方向和强度：Sobel，强度就是二范数，方向就是argtan(gy/gx)
3、非极大值抑制，消除边缘检测带来的杂散影响，抑制就是指非极大值的结果直接抛弃:NMS Non-Maximum Suppression
4、双阈值检测确定真实的和潜在的边缘
4、抑制孤立的弱边缘完成边缘检测

非极大值抑制：
（1）绝大部分人脸检测器的核心是分类器，即给定一个尺寸固定图片，即窗口，分类器判断是或者不是人脸；
（2）将分类器进化为检测器的关键是：在原始图像上从多个尺度产生窗口，并resize到固定尺寸，然后送给分类器做判断。最常用的方法是滑动窗口。
例如在行人检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分数。
但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。
这时就需要用到NMS来选取那些邻域里分数最高（是行人的概率最大），并且抑制那些分数低的窗口。
NMS在计算机视觉领域有着非常重要的应用，如视频边缘检测、目标检测、数据挖掘、3D重建、目标识别以及纹理分析等。
实现：
在边缘检测中，根据一个像素点周围八个方向的梯度值，如果当前像素点的梯度比其梯度方向前后两个像素点的梯度都大，那该像素点就是一个边界，
边界的方向为梯度的垂直方向

双阈值检测：梯度值>maxVal,该像素点处理为边界
          minVal < 梯度值 < maxVal，连有边界就保留，否则舍弃
          梯度值 < minVal,舍弃
minVal过小时：检测出更多的边界，边界可能没那么明显
minVal过大时：检测出的边界质量较高，但可能不全
maxVal和minVal需要指定
'''
img = cv2.imread('girl.jpg')
img = cv2.resize(img,(320,320))
canny1 = cv2.Canny(img,20,50)
canny2 = cv2.Canny(img,50,80)
cv2.imshow('1',canny1)
cv2.imshow('2',canny2)
cv2.waitKey(0)
cv2.destroyAllWindows()

'''
图像金字塔：用于图像特征提取，类似于卷积层
图像shape逐层改变
向下采样：shape降低
向上采样：shape增大
高斯金字塔向下采样：1、高斯核卷积
                 2、去除偶数行偶数列
高斯金字塔向上采样：1、插行，插列，填充0
                 2、高斯核卷积          
'''
img = cv2.imread('girl.jpg')
img = cv2.resize(img,(320,320))
pyrD = cv2.pyrDown(img)
pyrD_U = cv2.pyrUp(pyrD)
cv2.imshow('1',img)
cv2.imshow('2',pyrD_U)
# 拉普拉斯金字塔：先down再up，然后原始-pyrDown-Up，输出
pyrL = img - pyrD_U
pryL = cv2.convertScaleAbs(pyrL)
cv2.imshow('3',pyrL)
cv2.waitKey(0)
cv2.destroyAllWindows()


import cv2
import numpy as np
from cv2 import BORDER_CONSTANT, THRESH_BINARY, THRESH_BINARY_INV, RETR_TREE, CHAIN_APPROX_NONE

'''
图像轮廓：
1、将图像转为二值图像
2、检测轮廓
3、绘制了轮廓
'''
img = cv2.imread('girl.jpg')
img  = cv2.resize(img,(320,320))

# 二值处理
gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)
ret,thresh = cv2.threshold(gray,127,255,THRESH_BINARY)
# cv2.imshow('s',thresh)
# cv2.waitKey(0)
# 轮廓检测
contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)
             # 检测所有轮廓，     并重构嵌套轮廓的整个层次。      # 轮廓的所有点都保留
             # contours就是轮廓
print(np.array(contours,dtype=object).size)
# print(contours)
# 绘制轮廓
res = cv2.drawContours(img.copy(),contours,-1,(255,127,255),2)
cv2.imshow('ss',res)
cv2.waitKey(0)
# 可以对轮廓进行各种计算，比如求面积，周长(第二个参数：是否闭合)
cnt = contours[1]
print(cv2.contourArea(cnt),cv2.arcLength(cnt,True))
# 轮廓近似：防止把所有毛刺都算做轮廓，用直线代替曲线，第二个参数指定近似程度，
# 比如一个轮廓曲线，只用一个直线近似时，最远的点如果小于这个值，那么就可以用一条直线近似，否则以这个点为中心，绘制两条直线近似轮廓曲线

'''
模板匹配：将一个图像与一个模板匹配，找到图像与模板最像的那个部分
'''

import cv2
import numpy as np
from cv2 import BORDER_CONSTANT, THRESH_BINARY, THRESH_BINARY_INV, RETR_TREE, CHAIN_APPROX_NONE

'''
银行卡号识别：
1、对模板进行轮廓检测，获取轮廓的外接矩形，把矩形进行resize
2、对银行卡操作：二值图转换
3、检测大致轮廓
4、对大致轮廓进行定窗口大小的模板匹配
'''
def getContours(thresh):
    contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]
    boundingBoxs = [cv2.boundingRect(c) for c in contours]
    # cv2.imshow('1',thresh)
    # cv2.imshow('2',res)
    # cv2.imshow('3',number_template)
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()
    i = 0
    #(contours,boundingBoxs) = zip(*sorted(zip(contours,boundingBoxs),
    #                                     key=lambda b : b[1][i],reverse=reverse))
    return contours,boundingBoxs

def main():
    # 模板处理
    number_template = cv2.imread('number_template.jpg')
    gray = cv2.cvtColor(number_template, cv2.COLOR_RGB2GRAY)
    thresh = cv2.threshold(gray, 63, 255, cv2.THRESH_BINARY_INV)[1]
    digits = {}
    number_template = cv2.imread('number_template.jpg')
    contours, boundingBoxs = getContours(thresh)
    print(np.array(contours).shape)
    for (i,c) in enumerate(contours):
        (x,y,w,h)  = cv2.boundingRect(c)
        # print(x,y,w,h)
        roi = thresh[y:y+h,x:x+w]
        roi = cv2.resize(roi, (64, 96))
        digits[i] = roi
        res = cv2.drawContours(number_template.copy(), c, -1, (0, 0, 255), 2)
        # cv2.imshow('2',res)
        # cv2.waitKey(0)
        # cv2.destroyAllWindows()

    dictionary = {0:7,1:5,2:9,3:8,4:6,5:4,6:3,7:2,8:1,9:0}

    # 读入数据处理：先找到数字区域
    card = cv2.imread('card6.jpg')
    card = cv2.resize(card,(960,600))
    gray = cv2.cvtColor(card,cv2.COLOR_RGB2GRAY)
    # thresh  =cv2.threshold(gray,127,255,cv2.THRESH_BINARY)[1]
    # 形态学处理
    rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT,(15,3))
    sqKernel = cv2.getStructuringElement(cv2.MORPH_RECT,(9,9))
    # 突出文字部分
    tophat = cv2.morphologyEx(gray,cv2.MORPH_TOPHAT,kernel=rectKernel)
    sobelX = cv2.Sobel(tophat, ddepth=cv2.CV_32F, dx=1,dy=0)
    sobelX = cv2.convertScaleAbs(sobelX)
    # 闭操作，将文字连在一起
    gradX = cv2.morphologyEx(sobelX,cv2.MORPH_CLOSE,kernel=sqKernel)
    thresh = cv2.threshold(gradX,0,255, cv2.THRESH_BINARY|cv2.THRESH_OTSU)[1]
    # 闭的还不够，再闭一次
    cardA = cv2.morphologyEx(thresh,cv2.MORPH_CLOSE,kernel=sqKernel)
    # 找轮廓
    contours, boundingBoxs = getContours(cardA)
    res = cv2.drawContours(card.copy(),contours,-1,(0,0,255),2)
    cv2.imshow('9',res)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

    # 轮廓过滤，整个图像中有很多轮廓，通过轮廓外接矩形的长宽比，过滤不规则的轮廓，将数字方框的坐标保存造locs中
    locs = []
    for (i,c) in enumerate(contours):
        (x,y,w,h)  = cv2.boundingRect(c)
        # print(x,y,w,h)
        ar = w / float(h)
        if ar > 2.0 and ar < 5:
            if((w > 50 and w < 100) and (h > 20 and h < 50)) :
                res = cv2.drawContours(card.copy(), c, -1, (0, 0, 255), 2)
                locs.append([x,y,w,h])
                # cv2.imshow('res', res)
                # cv2.waitKey(0)
                # cv2.destroyAllWindows()
    res = cv2.drawContours(card.copy(), contours, -1, (0, 0, 255), 2)
    # print(np.array(locs).shape)
    # cv2.imshow('1',gray)
    # cv2.imshow('2',cardA)
    # cv2.imshow('3',res)
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()
    # print(locs)
    # 数字方框里有4个数字，再分一下
    for (i, (gx,gy,gw,gh)) in enumerate(locs):
        groupOut = []
        # 先把gray的数字方块找到
        group = gray[gy-5:gy+gh+5, gx-5:gx+gw+5]
        # 二值化
        thresh = cv2.threshold(group,0,255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)[1]
        # 检测轮廓
        cnts, boundingBox = getContours(thresh)
        # res = cv2.drawContours(group.copy(),cnts,-1,(0,0,255),1)
        # cv2.imshow('4',res)
        # cv2.waitKey(0)
        # cv2.destroyAllWindows()

        # 对每一个轮廓内的数字进行模板匹配
        for c in cnts:
            (x,y,w,h) = cv2.boundingRect(c)
            roi = group[y:y+h,x:x+h]
            roi = cv2.resize(roi,(64,96))
            scores = []
            for (digit, digitROI) in digits.items():
                # 当前数字与依次与模板中的数字匹配，单次匹配结果为result
                result = cv2.matchTemplate(roi,digitROI,
                                           cv2.TM_CCOEFF)
                # 匹配结果中只需要取最大的一个分值即可，因为模板与数字shape一样，所以每一的result只有一个数
                # 因为对0-9都进行了匹配，所以最后的socres为10个数
                # print('result',result)
                (_, score, _, _) = cv2.minMaxLoc(result)
                # print('score',score)
                scores.append(score)
                # 匹配结果中最大的那个位置就是识别结果
            # print(scores)
            numIndex = (np.argmax(scores))
            result  = dictionary[int(numIndex)]
            # print('numIndex',numIndex,numIndex.dtype)
            print('result',result)
            groupOut.append(result)
            res = cv2.drawContours(group.copy(),c,-1,(0,0,255),2)
            cv2.imshow('4',res)
            cv2.waitKey(0)
            cv2.destroyAllWindows()
        print(groupOut)

if __name__ == '__main__':
    main()
    
    
    
import cv2
import numpy as np
from cv2 import BORDER_CONSTANT, THRESH_BINARY, THRESH_BINARY_INV, RETR_TREE, CHAIN_APPROX_NONE

'''
角点：x方向和y方向灰度值剧烈变化，两个方向梯度很大的像素点。
角点比边界更容易定位
Harris角点检测：
1、像素点移动以后的灰度的变化程度：像素点(x,y)移动Δx和Δy以后的自相似性，会有8个新的像素点：
    对于像素点(u,v),自相似度c(u,v,Δx,Δy) = (I(u,v)-I(u+Δx,v+Δy))^2   I为灰度级
    对于滑动窗口(x,y),自相似度c(x,y,Δx,Δy) = sum(w(u,v)*(I(u,v)-I(u+Δx,v+Δy))^2)   其中(u,v)为窗口(x,y)中的所有像素点
                                            w(u,v)可以是常数，也可以是高斯加劝
    一阶泰勒展开：
    I(u+Δx,v+Δy) = I(u,v) + Ix(u,v)*Δx + Iy(u,v)*yx  Ix：I对x的偏导数
    (I(u,v)-I(u+Δx,v+Δy))^2 = (Ix(u,v)*Δx + Iy(u,v)*Δy)^2
    Ix(u,v)*Δx + Iy(u,v)*Δy = (Ix(u,v),Iy(u,v))* [Δx;Δy]
'''




'''
img = cv2.imread('dog.jpg')
gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)
gray = np.array(gray,dtype=np.float32)  #必须要转一下格式
cornerHarris = cv2.cornerHarris(gray,3,3,0.04)
#                图源数据，必须是float格式灰度图像，blockSize：检测窗口大小 ,ksize求梯度的算子大小3，就行，最后参数k，默认0.04
# 结果是每个点的R值，阈值设置一般是与最大值相比，一定是个角点
print(gray.shape,gray.dtype)
print(cornerHarris.shape,cornerHarris.dtype)
img[cornerHarris>0.001*cornerHarris.max()]=[0,0,255]
cv2.imshow('1',img)
cv2.waitKey(0)
'''

'''
SIFT算法：（尺度不变特征变换算法）图形平移特征不变性算法，非常常用，FFT
CV模型需要对目标尺度有适应性，即在不同分辨率下辨识出相同的特征
高斯滤波：相同分辨率下的不同标准差滤波，
高斯多分辨率金字塔：在不同分辨率下识别出相同特征，在不同分辨率下都进行高斯滤波
高斯差分金字塔：DOG：difference of Gaussian:相同分别率，不同高斯滤波下的
高斯多分辨率金字塔每一层包含不同标准差下高斯滤波的图像，两两相减，生成一个差分结果，5个图像，生成4个差分结果
             差分结果构成的金字塔就是高斯差分金字塔
差分结果中最大值数值较大的，就是重要的特征
DOG定义公式

sift算法（尺度不变特征变换）流程要懂，openCV现在因为专利问题，我们用不了了，
'''

img = cv2.imread('dog.jpg')
img1 = img.copy()
img2 = img.copy()
gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
g1 = cv2.GaussianBlur(gray,(31,31),sigmaX=1,sigmaY=1)
g2 = cv2.GaussianBlur(gray,(31,31),sigmaX=5,sigmaY=5)
# 创建对象
sift= cv2.SIFT.create()
# 计算关键点:链表
kp1 = sift.detect(g1,None)
kp2 = sift.detect(g2,None)
# 绘制关键点
img1 = cv2.drawKeypoints(gray,kp1,img1)
img2 = cv2.drawKeypoints(g2,kp2,img2)
cv2.imshow('3',img1)
cv2.imshow('4',img2)
cv2.waitKey(0)
cv2.destroyAllWindows()
# 计算特征向量：关键点位置，特征向量
kp,des = sift.compute(g1,kp1)
print(np.array(kp).shape,des.shape)
